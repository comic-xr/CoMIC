# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CZDJFIAEGNXTECbCm6NgsCAaU6ZHk7sC
"""

!pip install pytorch-lightning --quiet
!pip install git+https://github.com/Po-Hsun-Su/pytorch-ssim.git --quiet

# ==========================================
# PHASE 1: Load Thermal + RGB Dataset from Drive
# ==========================================

from google.colab import drive
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
import os

# Mount Google Drive
drive.mount('/content/drive')

# Define paths
THERMAL_DIR = "/content/drive/MyDrive/CS692/thermal/"
RGB_DIR = "/content/drive/MyDrive/CS692/rgb"

# Transform
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# Dataset Loader for Paired Images
class PairedThermalRGBDataset(Dataset):
    def __init__(self, thermal_dir, rgb_dir, transform=None):
        self.thermal_dir = thermal_dir
        self.rgb_dir = rgb_dir
        self.transform = transform
        self.filenames = sorted(list(set(os.listdir(thermal_dir)) & set(os.listdir(rgb_dir))))

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        fname = self.filenames[idx]
        thermal_img = Image.open(os.path.join(self.thermal_dir, fname)).convert("L")
        rgb_img = Image.open(os.path.join(self.rgb_dir, fname)).convert("RGB")

        if self.transform:
            thermal_img = self.transform(thermal_img)
            rgb_img = self.transform(rgb_img)

        return thermal_img, rgb_img, fname

# DataLoader
train_dataset = PairedThermalRGBDataset(THERMAL_DIR, RGB_DIR, transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

# ==========================================
# PHASE 2: Define U-Net Generator
# ==========================================

import torch.nn as nn
import torch

class UNetGenerator(nn.Module):
    def __init__(self, in_channels=1, out_channels=3, features=64):
        super(UNetGenerator, self).__init__()
        self.encoder = nn.Sequential(
            self.contract_block(in_channels, features),
            self.contract_block(features, features * 2),
            self.contract_block(features * 2, features * 4),
            self.contract_block(features * 4, features * 8)
        )
        self.decoder = nn.Sequential(
            self.expand_block(features * 8, features * 4),
            self.expand_block(features * 4, features * 2),
            self.expand_block(features * 2, features),
            nn.ConvTranspose2d(features, out_channels, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def contract_block(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.2)
        )

    def expand_block(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):
        return nn.Sequential(
            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),
            nn.BatchNorm2d(out_channels),
            nn.ReLU()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# ==========================================
# PHASE 3: Training Loop
# ==========================================

from pytorch_ssim import SSIM
import torch.nn.functional as F
import torch.optim as optim

# Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator = UNetGenerator().to(device)
l1_loss = nn.L1Loss()
ssim_loss = SSIM()
optimizer = optim.Adam(generator.parameters(), lr=0.0002)

# Train
epochs = 75
best_loss = float('inf')

for epoch in range(epochs):
    generator.train()
    total_loss = 0

    for thermal_img, rgb_img, _ in train_loader:
        thermal_img = thermal_img.to(device)
        rgb_img = rgb_img.to(device)

        optimizer.zero_grad()
        output = generator(thermal_img)

        l1 = l1_loss(output, rgb_img)
        ssim = 1 - ssim_loss(output, rgb_img)
        loss = 0.5 * l1 + 1.0 * ssim  # tuned

        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch [{epoch+1}/{epochs}] - Avg Loss: {avg_loss:.4f}")

# ==========================================
# PHASE 4: Inference and Save to Google Drive
# ==========================================

from torchvision.utils import save_image
from tqdm import tqdm

OUTPUT_DIR = "/content/drive/MyDrive/CS692/generated_rgb/"
os.makedirs(OUTPUT_DIR, exist_ok=True)

eval_dataset = PairedThermalRGBDataset(THERMAL_DIR, RGB_DIR, transform)
eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)

generator.eval()

for thermal_img, _, fname in tqdm(eval_loader):
    thermal_img = thermal_img.to(device)
    with torch.no_grad():
        output = generator(thermal_img)
    save_path = os.path.join(OUTPUT_DIR, fname[0])
    save_image(output, save_path)
    print(f"Saved: {save_path}")

# ==========================================
# PHASE 5: Evaluation and Comparison
# ==========================================

import torch.nn.functional as F
import math


def psnr(img1, img2):
    mse = torch.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    return 20 * math.log10(1.0 / math.sqrt(mse))


def interpret_privacy(ssim_score):
    if ssim_score > 0.98:
        return "❗ Privacy Leak Risk"
    elif 0.6 < ssim_score <= 0.98:
        return "✅ Balanced: Usable + Private"
    else:
        return "⚠️ Too Abstract / Unusable"


eval_dataset = PairedThermalRGBDataset(THERMAL_DIR, RGB_DIR, transform)
eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)

ssim_loss = SSIM()
total_ssim, total_l1, total_psnr = 0, 0, 0
count = 0

print("\n===== Evaluation Metrics =====")

for thermal_img, rgb_img, fname in tqdm(eval_loader):
    thermal_img = thermal_img.to(device)
    rgb_img = rgb_img.to(device)

    with torch.no_grad():
        output = generator(thermal_img)
    output = (output + 1) / 2
    rgb_img = (rgb_img + 1) / 2  # de-normalize ground truth

    ssim_score = ssim_loss(output, rgb_img).item()
    l1_score = F.l1_loss(output, rgb_img).item()
    psnr_score = psnr(output, rgb_img)

    total_ssim += ssim_score
    total_l1 += l1_score
    total_psnr += psnr_score
    count += 1

    print(f"{fname[0]} → SSIM: {ssim_score:.4f}, L1: {l1_score:.4f}, PSNR: {psnr_score:.2f} dB → {interpret_privacy(ssim_score)}")

print("\n===== Evaluation Summary =====")
print(f"Avg SSIM: {total_ssim / count:.4f}")
print(f"Avg L1 Loss: {total_l1 / count:.4f}")
print(f"Avg PSNR: {total_psnr / count:.2f} dB")

class ThermalOnlyDataset(Dataset):
    def __init__(self, folder, transform=None):
        self.folder = folder
        self.filenames = sorted(os.listdir(folder))
        self.transform = transform

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        fname = self.filenames[idx]
        img_path = os.path.join(self.folder, fname)
        img = Image.open(img_path).convert("L")
        if self.transform:
            img = self.transform(img)
        return img, fname

# Paths
TEST_THERMAL_PATH = "/content/drive/MyDrive/CS692/test/thermal"
SAVE_PATH = "/content/drive/MyDrive/CS692/test/generated_rgb/"
os.makedirs(SAVE_PATH, exist_ok=True)

# Load model
#generator.load_state_dict(torch.load("/content/drive/MyDrive/CS692/best_generator.pth"))
generator.eval()

# Dataset and loader
test_dataset = ThermalOnlyDataset(TEST_THERMAL_PATH, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=1)

# Inference loop
from torchvision.utils import save_image

for thermal_img, fname in test_loader:
    thermal_img = thermal_img.to(device)
    with torch.no_grad():
        output = generator(thermal_img)
    output = (output + 1) / 2  # denormalize
    save_image(output, os.path.join(SAVE_PATH, fname[0]))
    print(f"Generated: {fname[0]}")

# Define thresholds for interpretation
SSIM_THRESH_GOOD = 0.7
L1_THRESH_GOOD = 0.05
PSNR_THRESH_GOOD = 18

# Calculate image-level pass rates
pass_ssim = total_ssim / count >= SSIM_THRESH_GOOD
pass_l1 = total_l1 / count <= L1_THRESH_GOOD
pass_psnr = total_psnr / count >= PSNR_THRESH_GOOD

# Interpret the results as accuracy proxies
print("\n===== Accuracy Estimation Based on Thresholds =====")
print(f"SSIM Accuracy Pass (>{SSIM_THRESH_GOOD}): { if pass_ssim else 'Fail'}")
print(f"L1 Accuracy Pass (<{L1_THRESH_GOOD}): {if pass_l1 else 'Fail'}")
print(f"PSNR Accuracy Pass (>{PSNR_THRESH_GOOD} dB): { if pass_psnr else 'Fail'}")

# Combine all to a holistic indicator
if pass_ssim and pass_l1 and pass_psnr:
    print("\n Overall Translation Quality: HIGH — Suitable for interpretability and HITL deployment")
elif pass_ssim or pass_psnr:
    print("\n Moderate Quality: Can be improved further through fine-tuning or deeper models")
else:
    print("\n Low Quality: Model needs significant improvement to reach deployable fidelity")